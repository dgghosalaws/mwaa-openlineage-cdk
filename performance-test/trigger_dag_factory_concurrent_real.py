"""
Master Trigger DAG for DAG Factory Concurrent Real Load Test

This DAG triggers all DAG Factory concurrent test DAGs simultaneously.
ALL DAGs start at once with NO delays for TRUE concurrent load testing.

Configuration:
- Generated by: generate_dag_factory_config_real.py --tasks <N>
- Default: 65 DAGs × 31 tasks = 2015 actual task instances
- Task duration: 2 minutes
- NO wave delays - all start simultaneously

This configuration is optimized for scheduler throughput - 65 DAGs can start
simultaneously, ensuring true concurrent load.

Usage:
1. Generate config: python generate_dag_factory_config_real.py --tasks 2000
2. Upload files to S3
3. Wait for DAG parsing (2-5 minutes)
4. Trigger this DAG manually in Airflow UI
5. Monitor CloudWatch dashboard for metrics
"""

from airflow import DAG
from airflow.operators.trigger_dagrun import TriggerDagRunOperator
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import logging
import yaml
import os

# Default arguments
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 0,
}

# Read config to determine number of DAGs
config_file = os.path.join(os.path.dirname(__file__), "dag_factory_config_concurrent_real.yaml")
try:
    with open(config_file, 'r') as f:
        config = yaml.safe_load(f)
    num_dags = len(config)
    # Calculate total tasks from first DAG
    first_dag = list(config.values())[0]
    tasks_per_dag = len([t for t in first_dag['tasks'] if t['task_id'] != 'wave_delay'])
    total_tasks = num_dags * tasks_per_dag
except Exception as e:
    # Fallback to defaults if config can't be read
    num_dags = 65
    tasks_per_dag = 31
    total_tasks = 2015

# Create DAG
dag = DAG(
    'trigger_dag_factory_concurrent_real_test',
    default_args=default_args,
    description=f'Master trigger for DAG Factory Concurrent Load Test - {total_tasks} concurrent tasks',
    schedule=None,
    start_date=datetime(2024, 1, 1),
    catchup=False,
    max_active_runs=1,
    is_paused_upon_creation=False,
    tags=['dag-factory-test', 'concurrent-test-real', 'master-trigger', 'performance', 'real-load'],
)


def log_test_start(**context):
    """Log test start information"""
    logger = logging.getLogger(__name__)
    logger.info("=" * 80)
    logger.info("DAG FACTORY CONCURRENT LOAD TEST - REAL TASKS - STARTING")
    logger.info("=" * 80)
    logger.info(f"⚠️  TRUE CONCURRENT LOAD TEST - ALL ~{total_tasks} TASKS AT ONCE!")
    logger.info("")
    logger.info("Test Configuration:")
    logger.info(f"  - {num_dags} DAGs × {tasks_per_dag} REAL tasks = {total_tasks} ACTUAL task instances")
    logger.info("  - Task duration: 2 minutes")
    logger.info("  - NO wave delays - all start simultaneously")
    logger.info("  - Total test duration: ~2 minutes")
    logger.info("")
    logger.info("Optimization:")
    logger.info(f"  - {num_dags} DAGs (optimized for scheduler throughput)")
    logger.info(f"  - {tasks_per_dag} tasks per DAG")
    logger.info("  - Based on observed scheduler throughput")
    logger.info("")
    logger.info("Expected Behavior:")
    logger.info("  - Worker utilization jumps to high % immediately")
    logger.info(f"  - All {total_tasks} tasks run concurrently")
    logger.info("  - Test completes in ~2 minutes")
    logger.info("")
    logger.info(f"Triggering all {num_dags} DAGs now...")
    logger.info("=" * 80)
    return {'test_start_time': datetime.now().isoformat()}


def log_test_complete(**context):
    """Log test completion"""
    logger = logging.getLogger(__name__)
    logger.info("=" * 80)
    logger.info("DAG FACTORY CONCURRENT LOAD TEST - REAL TASKS - ALL DAGS TRIGGERED")
    logger.info("=" * 80)
    logger.info(f"All {num_dags} DAGs have been triggered successfully")
    logger.info("")
    logger.info("Next Steps:")
    logger.info("  1. Monitor CloudWatch dashboard for metrics")
    logger.info("  2. Check worker utilization")
    logger.info(f"  3. Verify all {total_tasks} tasks are running")
    logger.info("  4. Check individual DAG runs in Airflow UI")
    logger.info("  5. Wait ~2 minutes for test completion")
    logger.info("")
    logger.info("Expected Results:")
    logger.info(f"  - All {total_tasks} tasks running concurrently")
    logger.info("  - High worker utilization")
    logger.info("  - Test completes in ~2 minutes")
    logger.info("=" * 80)
    return {'test_trigger_complete': datetime.now().isoformat()}


# Start task
start_task = PythonOperator(
    task_id='log_test_start',
    python_callable=log_test_start,
    dag=dag,
)

# Generate trigger tasks for all DAGs
# All DAGs are in wave 1 (no delays)
trigger_tasks = []

for dag_num in range(num_dags):
    dag_id = f"factory_concurrent_real_dag_{dag_num:03d}"
    
    trigger_task = TriggerDagRunOperator(
        task_id=f'trigger_{dag_id}',
        trigger_dag_id=dag_id,
        wait_for_completion=False,  # Don't wait, trigger all simultaneously
        dag=dag,
    )
    
    trigger_tasks.append(trigger_task)
    start_task >> trigger_task

# End task
end_task = PythonOperator(
    task_id='log_test_complete',
    python_callable=log_test_complete,
    dag=dag,
)

# Connect all trigger tasks to end task
for trigger_task in trigger_tasks:
    trigger_task >> end_task
